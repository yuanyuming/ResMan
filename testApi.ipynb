{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is a minimal example of using Tianshou with MARL to train agents.\n",
    "\n",
    "Author: Will (https://github.com/WillDudley)\n",
    "\n",
    "Python version used: 3.8.10\n",
    "\n",
    "Requirements:\n",
    "pettingzoo == 1.22.0\n",
    "git+https://github.com/thu-ml/tianshou\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from tianshou.data import Collector, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import BasePolicy, DQNPolicy, MultiAgentPolicyManager, RandomPolicy\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils.net.common import Net\n",
    "\n",
    "from pettingzoo.classic import tictactoe_v3\n",
    "\n",
    "\n",
    "def _get_agents(\n",
    "    agent_learn: Optional[BasePolicy] = None,\n",
    "    agent_opponent: Optional[BasePolicy] = None,\n",
    "    optim: Optional[torch.optim.Optimizer] = None,\n",
    ") -> Tuple[BasePolicy, torch.optim.Optimizer, list]:\n",
    "    env = _get_env()\n",
    "    observation_space = (\n",
    "        env.observation_space[\"observation\"]\n",
    "        if isinstance(env.observation_space, gym.spaces.Dict)\n",
    "        else env.observation_space\n",
    "    )\n",
    "    if agent_learn is None:\n",
    "        # model\n",
    "        net = Net(\n",
    "            state_shape=observation_space.shape or observation_space.n,\n",
    "            action_shape=env.action_space.shape or env.action_space.n,\n",
    "            hidden_sizes=[128, 128, 128, 128],\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if optim is None:\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "        agent_learn = DQNPolicy(\n",
    "            model=net,\n",
    "            optim=optim,\n",
    "            discount_factor=0.9,\n",
    "            estimation_step=3,\n",
    "            target_update_freq=320,\n",
    "        )\n",
    "\n",
    "    if agent_opponent is None:\n",
    "        agent_opponent = RandomPolicy()\n",
    "\n",
    "    agents = [agent_opponent, agent_learn]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    return policy, optim, env.agents\n",
    "\n",
    "\n",
    "def _get_env():\n",
    "    \"\"\"This function is needed to provide callables for DummyVectorEnv.\"\"\"\n",
    "    return PettingZooEnv(tictactoe_v3.env())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======== Step 1: Environment setup =========\n",
    "    train_envs = DummyVectorEnv([_get_env for _ in range(10)])\n",
    "    test_envs = DummyVectorEnv([_get_env for _ in range(10)])\n",
    "\n",
    "    # seed\n",
    "    seed = 1\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    train_envs.seed(seed)\n",
    "    test_envs.seed(seed)\n",
    "\n",
    "    # ======== Step 2: Agent setup =========\n",
    "    policy, optim, agents = _get_agents()\n",
    "\n",
    "    # ======== Step 3: Collector setup =========\n",
    "    train_collector = Collector(\n",
    "        policy,\n",
    "        train_envs,\n",
    "        VectorReplayBuffer(20_000, len(train_envs)),\n",
    "        exploration_noise=True,\n",
    "    )\n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    # policy.set_eps(1)\n",
    "    train_collector.collect(n_step=64 * 10)  # batch size * training_num\n",
    "\n",
    "    # ======== Step 4: Callback functions setup =========\n",
    "    def save_best_fn(policy):\n",
    "        model_save_path = os.path.join(\"log\", \"rps\", \"dqn\", \"policy.pth\")\n",
    "        os.makedirs(os.path.join(\"log\", \"rps\", \"dqn\"), exist_ok=True)\n",
    "        torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        return mean_rewards >= 0.6\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        policy.policies[agents[1]].set_eps(0.1)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        policy.policies[agents[1]].set_eps(0.05)\n",
    "\n",
    "    def reward_metric(rews):\n",
    "        return rews[:, 1]\n",
    "\n",
    "    # ======== Step 5: Run the trainer =========\n",
    "    result = offpolicy_trainer(\n",
    "        policy=policy,\n",
    "        train_collector=train_collector,\n",
    "        test_collector=test_collector,\n",
    "        max_epoch=50,\n",
    "        step_per_epoch=1000,\n",
    "        step_per_collect=50,\n",
    "        episode_per_test=10,\n",
    "        batch_size=64,\n",
    "        train_fn=train_fn,\n",
    "        test_fn=test_fn,\n",
    "        stop_fn=stop_fn,\n",
    "        save_best_fn=save_best_fn,\n",
    "        update_per_step=0.1,\n",
    "        test_in_train=False,\n",
    "        reward_metric=reward_metric,\n",
    "    )\n",
    "\n",
    "    # return result, policy.policies[agents[1]]\n",
    "    print(f\"\\n==========Result==========\\n{result}\")\n",
    "    print(\"\\n(the trained policy can be accessed via policy.policies[agents[1]])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_benchmark(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Environment\n",
    "env = Environment.VehicleJobSchedulingEnvACE()\n",
    "from pettingzoo.test import performance_benchmark\n",
    "import cProfile\n",
    "cProfile.run(\"performance_benchmark(env)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.utils.wrappers import BaseWrapper\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "import Environment\n",
    "from tianshou.env import PettingZooEnv\n",
    "env = Environment.VehicleJobSchedulingEnvACE()\n",
    "\n",
    "\n",
    "env = BaseWrapper(env)\n",
    "\n",
    "env = PettingZooEnv(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _, _, _,_= env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import flatten,flatten_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unknown space: `Dict('avail_slot': Box(0, 100, (10, 2), int8), 'request_job': Dict('res_vec': MultiDiscrete([20 30]), 'len': Discrete(10), 'priority': Discrete(6)))`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flatten_space(env\u001b[39m.\u001b[39;49mobservation_space)\n",
      "File \u001b[0;32m/root/anaconda3/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/ResMan/man/lib/python3.9/site-packages/gym/spaces/utils.py:199\u001b[0m, in \u001b[0;36mflatten_space\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m@singledispatch\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflatten_space\u001b[39m(space: Space) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Box:\n\u001b[1;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Flatten a space into a single ``Box``.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[39m    This is equivalent to ``flatten()``, but operates on the space itself. The\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m        True\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown space: `\u001b[39m\u001b[39m{\u001b[39;00mspace\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unknown space: `Dict('avail_slot': Box(0, 100, (10, 2), int8), 'request_job': Dict('res_vec': MultiDiscrete([20 30]), 'len': Discrete(10), 'priority': Discrete(6)))`"
     ]
    }
   ],
   "source": [
    "flatten_space(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unknown space: `Dict('avail_slot': Box(0, 100, (10, 2), int8), 'request_job': Dict('res_vec': MultiDiscrete([20 30]), 'len': Discrete(10), 'priority': Discrete(6)))`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flatten(env\u001b[39m.\u001b[39;49mobservation_space, obs)\n",
      "File \u001b[0;32m/root/anaconda3/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/ResMan/man/lib/python3.9/site-packages/gym/spaces/utils.py:69\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(space, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m@singledispatch\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflatten\u001b[39m(space: Space[T], x: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Flatten a data point from a space.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This is useful when e.g. points from spaces must be passed to a neural\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m    ``gym.spaces``.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown space: `\u001b[39m\u001b[39m{\u001b[39;00mspace\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unknown space: `Dict('avail_slot': Box(0, 100, (10, 2), int8), 'request_job': Dict('res_vec': MultiDiscrete([20 30]), 'len': Discrete(10), 'priority': Discrete(6)))`"
     ]
    }
   ],
   "source": [
    "flatten(env.observation_space, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, [100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100\n",
       " 100 100   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
       "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
       "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
       "   1   1   1   1   1   1   1   1   1   1   1   1   1   1], (86,), int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obss = obs.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61, 70, 29,  8, 60, 72, 96, 23, 58, 32, 37, 97,  5, 27, 26, 90,  6,\n",
       "       61, 17, 38,  0,  0,  1,  1,  1,  0,  0,  1,  0,  1,  0,  0,  1,  1,\n",
       "        1,  0,  0,  1,  0,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,  1,  0,\n",
       "        0,  1,  1,  0,  0,  1,  0,  1,  0,  0,  1,  1,  1,  1,  1,  0,  1,\n",
       "        0,  1,  0,  0,  0,  1,  1,  1,  0,  1,  0,  0,  1,  0,  1,  1,  0,\n",
       "        1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,  36,  62,  95,  77,  33,  43,  89,  70,  85,  56,  80,  29,\n",
       "        67,   3,   0,  15,   4,  59,  92,   4,  25,   7,   0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.ravel(obss[\"avail_slot\"]),np.hstack([obss[\"request_job\"][item] for item in obss[\"request_job\"]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4, 25]), 7, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obss[\"request_job\"][item] for item in obss[\"request_job\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mconcatenate(([[ \u001b[39m4\u001b[39;49m, \u001b[39m25\u001b[39;49m], \u001b[39m7\u001b[39;49m, \u001b[39m0\u001b[39;49m]),axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)"
     ]
    }
   ],
   "source": [
    "np.concatenate(([[ 4, 25], 7, 0]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 25,  7,  0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([obss[\"request_job\"][item] for item in obss[\"request_job\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 0 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flatten_obs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([obss[key] \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m obss\u001b[39m.\u001b[39;49mkeys()])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 0 dimension(s)"
     ]
    }
   ],
   "source": [
    "flatten_obs = np.ravel(obss[\"avail_slot\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flaten_obs(obss):\n",
    "    return obss.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "man",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d652fbd7feb28eaf2ff622dc57929f599600a55ad62e1efe6c9f098053cf5e75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
